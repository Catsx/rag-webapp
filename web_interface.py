#!/usr/bin/env python3
"""
Web Interface for RAG - Catarina Cardoso
Creates a user-friendly web interface using Gradio
"""

import sys
from pathlib import Path
import gradio as gr
import os

# Add src directory to path
src_path = str(Path(__file__).parent / "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

from rag_pipeline import RAGPipeline

class RAGWebInterface:
    def __init__(self):
        self.rag = None
        self.indexed_sources = []
        
    def initialize_rag(self, api_key):
        """Initialize the RAG pipeline with API key."""
        try:
            if api_key and api_key.strip():
                self.rag = RAGPipeline(
                    openai_api_key=api_key.strip(),
                    temperature=0.1,
                    chunk_size=1000,
                    chunk_overlap=200
                )
                return "âœ… Pipeline RAG inicializada com sucesso!"
            else:
                self.rag = RAGPipeline(openai_api_key=None)
                return "âš ï¸ Pipeline RAG inicializada sem chave OpenAI (apenas pesquisa por similaridade)"
        except Exception as e:
            return f"âŒ Erro ao inicializar RAG: {str(e)}"
    
    def add_documents(self, files, urls_text):
        """Add documents and URLs to the RAG system."""
        if not self.rag:
            return "âŒ Por favor, inicia primeiro o RAG!", ""
        
        sources = []
        
        # Handle uploaded files
        if files:
            for file in files:
                sources.append(file.name)
        
        # Handle URLs
        if urls_text and urls_text.strip():
            urls = [url.strip() for url in urls_text.split('\n') if url.strip()]
            sources.extend(urls)
        
        if not sources:
            return "âŒ Nenhuma fonte fornecida!", ""
        
        try:
            results = self.rag.index_documents(sources)
            self.indexed_sources.extend(sources)
            
            success_msg = f"""âœ… Documentos indexados com sucesso!
            
ğŸ“Š Resultados:
â€¢ Documentos carregados: {results['documents_loaded']}
â€¢ Chunks criados: {results['chunks_created']}
â€¢ Fontes processadas: {results['sources_indexed']}

ğŸ“š Fontes atualmente indexadas:
{chr(10).join([f"â€¢ {source}" for source in self.indexed_sources])}
            """
            
            return success_msg, ""
            
        except Exception as e:
            return f"âŒ Erro ao indexar documentos: {str(e)}", ""
    
    def ask_question(self, question):
        """Ask a question to the RAG system."""
        if not self.rag:
            return "âŒ Por favor, inicia primeiro o RAG!"
        
        if not self.rag.is_indexed:
            return "âŒ Nenhum documento indexado! Por favor, adiciona primeiro os documentos."
        
        if not question or not question.strip():
            return "âŒ Por favor, faz uma pergunta!"
        
        try:
            # Always try similarity search first (works without OpenAI)
            docs = self.rag.get_similar_documents(question.strip(), k=3)
            
            if not docs:
                return "âŒ Nenhum conteÃºdo relevante encontrado para a tua pergunta."
            
            # Try full RAG query if LLM is available and has quota
            if self.rag.llm:
                try:
                    response = self.rag.query(question.strip())
                    
                    answer = f"""ğŸ¤– **Resposta IA:**
{response['answer']}

ğŸ“š **Fontes utilizadas:**
"""
                    if 'sources' in response:
                        for i, source in enumerate(response['sources'][:3], 1):
                            content_preview = source['content'][:150] + "..." if len(source['content']) > 150 else source['content']
                            source_info = source['metadata'].get('source', 'Desconhecida')
                            answer += f"\n{i}. **{source_info}**\n   {content_preview}\n"
                    
                    if 'token_usage' in response:
                        usage = response['token_usage']
                        answer += f"\nğŸ’° **Uso:** {usage['total_tokens']} tokens (${usage['total_cost']:.4f})"
                    
                    return answer
                    
                except Exception as llm_error:
                    # If LLM fails (quota issue), fall back to similarity search
                    if "quota" in str(llm_error).lower() or "429" in str(llm_error):
                        pass  # Continue to similarity search below
                    else:
                        return f"âŒ Erro LLM: {str(llm_error)}"
            
            # Similarity search results (always works)
            answer = f"""ğŸ” **ConteÃºdo Relevante Encontrado:**

**A Tua Pergunta:** {question.strip()}

"""
            
            for i, doc in enumerate(docs, 1):
                content_preview = doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content
                source_info = doc.metadata.get('source', 'Desconhecida')
                chunk_info = f"(Chunk {doc.metadata.get('chunk_id', 'N/A')})"
                
                answer += f"""**ğŸ“„ Resultado {i}: {source_info}** {chunk_info}
{content_preview}

---

"""
            
            answer += """ğŸ’¡ **Como obter respostas geradas por IA:**
â€¢ Adiciona uma chave API do OpenAI com quota disponÃ­vel
â€¢ Ou usa os resultados de similaridade acima para encontrar a tua resposta

âœ… **O teu sistema RAG estÃ¡ a funcionar perfeitamente para recuperaÃ§Ã£o de documentos!**"""
            
            return answer
                
        except Exception as e:
            return f"âŒ Erro ao processar pergunta: {str(e)}"
    
    def get_status(self):
        """Get RAG system status."""
        if not self.rag:
            return "âŒ RAG nÃ£o inicializado"
        
        stats = self.rag.get_pipeline_stats()
        
        status = f"""ğŸ“Š **Estado do Sistema RAG**

ğŸ”§ **ConfiguraÃ§Ã£o:**
â€¢ Modelo: {stats['configuration']['model_name']}
â€¢ Temperatura: {stats['configuration']['temperature']}
â€¢ Tamanho do chunk: {stats['configuration']['chunk_size']}
â€¢ Modelo de embeddings: {stats['configuration']['embedding_model']}

ğŸ“ˆ **EstatÃ­sticas de Uso:**
â€¢ Documentos carregados: {stats['usage_stats']['documents_loaded']}
â€¢ Chunks criados: {stats['usage_stats']['chunks_created']}
â€¢ Perguntas processadas: {stats['usage_stats']['queries_processed']}

ğŸƒ **Estado da Pipeline:**
â€¢ Indexado: {'âœ…' if stats['pipeline_status']['is_indexed'] else 'âŒ'}
â€¢ LLM DisponÃ­vel: {'âœ…' if stats['pipeline_status']['llm_available'] else 'âŒ'}
â€¢ Cadeia Q&A Pronta: {'âœ…' if stats['pipeline_status']['qa_chain_ready'] else 'âŒ'}

ğŸ“š **Fontes Indexadas:**
{chr(10).join([f"â€¢ {source}" for source in self.indexed_sources]) if self.indexed_sources else "Ainda nÃ£o hÃ¡ fontes indexadas"}
        """
        
        return status

def create_interface():
    """Create the Gradio web interface."""
    
    rag_interface = RAGWebInterface()
    
    with gr.Blocks(title="RAG - Catarina Cardoso", theme=gr.themes.Soft()) as app:
        
        gr.Markdown("""
        # ğŸ¤– RAG - Catarina Cardoso
        ### Catarina Cardoso
        
        Faz upload de documentos, adiciona links web e faz perguntas sobre o teu conteÃºdo!
        """)
        
        with gr.Tab("ğŸš€ ConfiguraÃ§Ã£o"):
            gr.Markdown("### Passo 1: Iniciar Sistema RAG")
            
            api_key_input = gr.Textbox(
                label="Chave API OpenAI (Opcional)", 
                placeholder="sk-proj-...", 
                type="password",
                info="Deixa vazio para usar apenas pesquisa por similaridade"
            )
            
            init_btn = gr.Button("Inicializar Sistema RAG", variant="primary")
            init_output = gr.Textbox(label="Estado da InicializaÃ§Ã£o", interactive=False)
            
            init_btn.click(
                rag_interface.initialize_rag,
                inputs=[api_key_input],
                outputs=[init_output]
            )
        
        with gr.Tab("ğŸ“š Adicionar Documentos"):
            gr.Markdown("### Passo 2: Adiciona os Teus Documentos e Fontes")
            
            with gr.Row():
                with gr.Column():
                    file_upload = gr.Files(
                        label="Upload de Ficheiros (PDF, DOCX, TXT)", 
                        file_types=[".pdf", ".docx", ".txt", ".md"]
                    )
                    
                with gr.Column():
                    urls_input = gr.Textbox(
                        label="URLs Web (uma por linha)",
                        placeholder="https://exemplo.com/artigo1\nhttps://exemplo.com/artigo2",
                        lines=5
                    )
            
            add_btn = gr.Button("Adicionar Documentos ao RAG", variant="primary")
            add_output = gr.Textbox(label="Resultados da IndexaÃ§Ã£o", lines=10, interactive=False)
            
            add_btn.click(
                rag_interface.add_documents,
                inputs=[file_upload, urls_input],
                outputs=[add_output, urls_input]
            )
        
        with gr.Tab("ğŸ’¬ Fazer Perguntas"):
            gr.Markdown("### Passo 3: Faz Perguntas Sobre os Teus Documentos")
            
            question_input = gr.Textbox(
                label="A Tua Pergunta",
                placeholder="Qual Ã© o tÃ³pico principal dos documentos?",
                lines=2
            )
            
            ask_btn = gr.Button("Fazer Pergunta", variant="primary")
            answer_output = gr.Textbox(label="Resposta", lines=15, interactive=False)
            
            ask_btn.click(
                rag_interface.ask_question,
                inputs=[question_input],
                outputs=[answer_output]
            )
            
            # Quick question examples
            gr.Markdown("### ğŸ’¡ Perguntas de Exemplo:")
            example_questions = [
                "Qual Ã© o tÃ³pico principal?",
                "Resume os pontos-chave",
                "Quais sÃ£o os benefÃ­cios mencionados?",
                "Quem sÃ£o as principais pessoas ou organizaÃ§Ãµes mencionadas?"
            ]
            
            for question in example_questions:
                example_btn = gr.Button(f"ğŸ“ {question}", size="sm")
                example_btn.click(
                    lambda q=question: q,
                    outputs=[question_input]
                )
        
        with gr.Tab("ğŸ“Š Estado"):
            gr.Markdown("### Estado do Sistema e EstatÃ­sticas")
            
            status_btn = gr.Button("Atualizar Estado", variant="secondary")
            status_output = gr.Textbox(label="Estado do Sistema RAG", lines=20, interactive=False)
            
            status_btn.click(
                rag_interface.get_status,
                outputs=[status_output]
            )
        
        gr.Markdown("""
        ---
        ### ğŸ“– Como Usar:
        1. **ConfiguraÃ§Ã£o**: Inicia o sistema RAG (com ou sem chave API OpenAI)
        2. **Adicionar Documentos**: Faz upload de ficheiros ou cola URLs web
        3. **Fazer Perguntas**: Faz perguntas sobre os teus documentos
        4. **Verificar Estado**: Monitoriza a saÃºde do sistema e estatÃ­sticas de uso
        
        ### ğŸ’¡ Dicas:
        - Sem chave API OpenAI: Vais obter resultados de pesquisa por similaridade
        - Com chave API OpenAI: Vais obter respostas completas geradas por IA
        - Formatos suportados: PDF, DOCX, TXT, Markdown, URLs Web
        """)
    
    return app

if __name__ == "__main__":
    # Check if gradio is installed
    try:
        import gradio
    except ImportError:
        print("A instalar Gradio para interface web...")
        os.system("pip3 install gradio")
        import gradio as gr
    
    print("ğŸš€ A iniciar Interface Web RAG...")
    print("ğŸ“± A interface vai abrir no teu navegador web")
    print("ğŸ”— TambÃ©m podes aceder em: http://localhost:7864")
    
    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7864,
        share=False,
        show_error=True,
        quiet=False
    )
